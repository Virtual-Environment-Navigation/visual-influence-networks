{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TDDC\n",
    "\n",
    "Input file(s):\n",
    "* `../data/csv/sayles_data_90pct.csv`\n",
    "\n",
    "Output file(s):\n",
    "* [Optional] `../data/pickle/h.p` & `../data/pickle/TDDC.p`\n",
    "    * TDDC[trial][seg] = respectively, scalor product *h* & TDDC values for each pair in a given segment. Shape: (N, N, num_tau, num_frames)\n",
    "    * The produced .p file is very large (36.26 GB). I didn't save it since it's not being used, but it can always be reproduced. To reproduce this, uncomment all the TDDC codes in the code below.\n",
    "* `../data/pickle/index.p`\n",
    "    * index[trial][seg] = tau indices for max TDDC values at every time t for each pair in a given segment. Shape: (N, N, num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment some lines to save h & TDDC values.\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import config\n",
    "from utils.get_TDDC import get_TDDC\n",
    "\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "h, TDDC = {}, {}\n",
    "index = {}\n",
    "\n",
    "for trial in df['trial'].unique():\n",
    "    print('trial', int(trial), end=' ')\n",
    "    trial_df = df[(df['trial']==trial)]\n",
    "    h[trial], TDDC[trial] = {}, {}\n",
    "    index[trial] = {}\n",
    "\n",
    "    print('-- segment', end=' ')\n",
    "\n",
    "    for seg in trial_df['segment'].unique():\n",
    "        print(seg, end=' ')\n",
    "        seg_df = trial_df[trial_df['segment']==seg]\n",
    "\n",
    "        ## get velocities for the segment (ignore the first frame with NaNs)\n",
    "        seg_xvel = seg_df.pivot(index='frame_segment', columns='ID', values='x_vel').to_numpy()[1:] # (num_frames, N)\n",
    "        seg_yvel = seg_df.pivot(index='frame_segment', columns='ID', values='y_vel').to_numpy()[1:]\n",
    "\n",
    "        ## compute TDDC & max tau\n",
    "        ## - h (scaler product) & TDDC : (N, N, num_tau, num_frames)\n",
    "        ## - index (indices of max tau) : (N, N, num_frames)\n",
    "        _, _, index[trial][seg] = get_TDDC(seg_xvel, seg_yvel, SAMP_FREQ=config.SAMP_FREQ)\n",
    "        # h[trial][seg],TDDC[trial][seg], index[trial][seg] = get_TDDC(seg_xvel, seg_yvel, SAMP_FREQ=config.SAMP_FREQ)\n",
    "    #     break\n",
    "    # break\n",
    "    print(end='\\n')\n",
    "\n",
    "if not os.path.exists('../data/pickle'):\n",
    "    os.makedirs('../data/pickle')\n",
    "\n",
    "print(\"saving...\")\n",
    "# pickle.dump(h, open('../data/pickle/sayles_h.p', 'wb'))\n",
    "# pickle.dump(TDDC, open('../data/pickle/sayles_TDDC.p', 'wb'))\n",
    "pickle.dump(index, open('../data/pickle/sayles_index.p', 'wb'))\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get network weights\n",
    "\n",
    "Input file(s):\n",
    "* `../data/csv/sayles_data_90pct.csv`\n",
    "* `../data/pickle/index.p` : TDDC tau indices \n",
    "\n",
    "Output file(s):\n",
    "* `../data/pickle/sayles_weights_unpruned_500ms.p` : network weights without any pruning.\n",
    "    * A[trial][seg] : (num_networks, N, N)\n",
    "* `../data/pickle/sayles_weights_pruned_500ms.p` : network weights after pruning is applied.\n",
    "    * A[trial][seg] : (num_networks, N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing network weights (window size: 4 s)\n",
      "trial 1 -- segment 1 2 3 \n",
      "trial 2 -- segment 1 2 3 4 5 \n",
      "trial 3 -- segment 1 2 3 4 \n",
      "trial 4 -- segment 1 2 3 4 5 \n",
      "trial 5 -- segment 1 2 3 (X) 4 5 \n",
      "trial 6 -- segment 1 2 3 4 5 \n",
      "trial 7 -- segment 1 2 5 7 \n",
      "trial 8 -- segment 1 2 3 4 5 \n",
      "trial 9 -- segment 1 2 4 5 \n",
      "trial 10 -- segment 1 3 4 \n",
      "trial 11 -- segment 1 2 3 \n",
      "trial 12 -- segment 1 2 4 \n",
      "\n",
      "saving...\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import config\n",
    "from utils.get_network import get_network_weights\n",
    "\n",
    "# ===== CHANGE THIS ========================================\n",
    "ntwk_window_size = 0.5  # config.NTWK_WINDOW_SIZE   # in s\n",
    "# ==========================================================\n",
    "\n",
    "## init\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "index = pickle.load( open( \"../data/pickle/index.p\", \"rb\" ) )\n",
    "# constant values\n",
    "SAMP_FREQ = config.SAMP_FREQ\n",
    "tau = config.TAU\n",
    "ntwk_window_size_ms = int(ntwk_window_size * 1000)\n",
    "\n",
    "print('computing network weights (window size:', ntwk_window_size, 's)')\n",
    "\n",
    "## compute network weights\n",
    "unpruned_weights, pruned_weights = {}, {}\n",
    "for trial in index.keys():\n",
    "    print('trial', int(trial), '-- segment', end=' ')\n",
    "    unpruned_weights[trial], pruned_weights[trial] = {}, {}\n",
    "    trial_df = df[(df['trial']==trial)]\n",
    "\n",
    "    for seg in index[trial].keys():\n",
    "        print(seg, end=' ')\n",
    "        seg_df = trial_df[trial_df['segment']==seg]\n",
    "\n",
    "        x = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                         values='x').to_numpy()\n",
    "        y = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                         values='y').to_numpy()\n",
    "        heading = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                               values='heading').to_numpy()\n",
    "        \n",
    "        seg_length = x.shape[0] / SAMP_FREQ     # length of the segment in seconds\n",
    "        # disregard the segment if too short\n",
    "        if (seg_length < ntwk_window_size/2):\n",
    "            print('(X)', end=' ')\n",
    "            continue\n",
    "        \n",
    "        # weights[trial][seg] : (num_networks, N, N)\n",
    "        unpruned_weights[trial][seg] = get_network_weights(index[trial][seg], \n",
    "                                                           x, y, heading, SAMP_FREQ, \n",
    "                                                           pruning=False,\n",
    "                                                           TAU=tau,\n",
    "                                                           NTWK_WINDOW_SIZE=ntwk_window_size)    \n",
    "        pruned_weights[trial][seg] = get_network_weights(index[trial][seg], \n",
    "                                                         x, y, heading, SAMP_FREQ, \n",
    "                                                         pruning=True,\n",
    "                                                         TAU=tau,\n",
    "                                                         NTWK_WINDOW_SIZE=ntwk_window_size)\n",
    "    print(end='\\n')\n",
    "\n",
    "\n",
    "print(\"\\nsaving...\")\n",
    "pickle.dump(unpruned_weights, \n",
    "            open(f'../data/pickle/sayles_weights_unpruned_{ntwk_window_size_ms}ms.p', 'wb'))\n",
    "pickle.dump(pruned_weights, \n",
    "            open(f'../data/pickle/sayles_weights_pruned_{ntwk_window_size_ms}ms.p', 'wb'))\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TDDC heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for every pair, every segment\n",
    "# NOTE: it will take forever, so I do not recommend running this.\n",
    "# instead, run it for a specific trial/segment (see the next code block)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from utils.get_TDDC import get_TDDC, plot_TDDC_ij\n",
    "\n",
    "# used for the title\n",
    "# from https://www.geeksforgeeks.org/how-to-print-superscript-and-subscript-in-python/\n",
    "def get_sub(x):\n",
    "    normal = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+-=()\"\n",
    "    sub_s = \"ₐ₈CDₑբGₕᵢⱼₖₗₘₙₒₚQᵣₛₜᵤᵥwₓᵧZₐ♭꜀ᑯₑբ₉ₕᵢⱼₖₗₘₙₒₚ૧ᵣₛₜᵤᵥwₓᵧ₂₀₁₂₃₄₅₆₇₈₉₊₋₌₍₎\"\n",
    "    res = x.maketrans(''.join(normal), ''.join(sub_s)) \n",
    "    return x.translate(res)\n",
    "\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "\n",
    "if not os.path.exists('../data/output'):\n",
    "    os.makedirs('../data/output')\n",
    "\n",
    "for trial in df['trial'].unique():\n",
    "    print('trial', int(trial), end=' ')\n",
    "    trial_df = df[(df['trial']==trial)]\n",
    "\n",
    "    print('-- segment', end=' ')\n",
    "\n",
    "    for seg in trial_df['segment'].unique():\n",
    "        print(seg, end=' ')\n",
    "        seg_df = trial_df[trial_df['segment']==seg]\n",
    "\n",
    "        start_t = min(seg_df.frame_segment.unique() * config.SAMP_FREQ)\n",
    "        end_t = max(seg_df.frame_segment.unique() * config.SAMP_FREQ)\n",
    "        \n",
    "        ## get velocities for the segment (ignore the first frame with NaNs)\n",
    "        seg_xvel = seg_df.pivot(index='frame_segment', columns='ID', values='x_vel').to_numpy()[1:] # (num_frames, N)\n",
    "        seg_yvel = seg_df.pivot(index='frame_segment', columns='ID', values='y_vel').to_numpy()[1:]\n",
    "\n",
    "        ## compute TDDC & max tau\n",
    "        ## - TDDC : (N, N, num_tau, num_frames)\n",
    "        ## - index (indices of max tau) : (N, N, num_frames)\n",
    "        _, TDDC, index = get_TDDC(seg_xvel, seg_yvel, SAMP_FREQ=config.SAMP_FREQ)\n",
    "        N = TDDC.shape[0]\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    # print(i+1,j+1)\n",
    "                    title = 'Trial'+str(trial)+' Seg'+str(seg)\n",
    "                    title += ': TDDC{}(t,$\\\\tau$)'.format(get_sub(str(i+1)+'-'+str(j+1)))\n",
    "                    for form in ['png','svg']:\n",
    "                        plot_TDDC_ij(TDDC[i,j,:,:], index[i,j,:],\n",
    "                                    SAMP_FREQ=config.SAMP_FREQ,\n",
    "                                    title=title,\n",
    "                                    saved=True,\n",
    "                                    output_folder=f'../output/sayles/{form}/TDDC_heatmaps/',\n",
    "                                    output_file=f'TDDC_trial{int(trial)}_seg{seg}_i{i+1}_j{j}',\n",
    "                                    output_format=form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only for a given trial/segment\n",
    "\n",
    "import pandas as pd\n",
    "import config\n",
    "from utils.get_TDDC import get_TDDC, plot_TDDC_ij\n",
    "\n",
    "# ===== change here =====\n",
    "trial = 1\n",
    "seg = 1\n",
    "# None to plot all, or a list of indices (ID - 1) to plot\n",
    "i_plotted = [0,8]     # None\n",
    "j_plotted = [8,0]     # None\n",
    "\n",
    "saved = True        # whether SSSto save or display the figures\n",
    "# =======================\n",
    "\n",
    "print(f'plotting figures for trial {trial} seg {seg} (saved in in ../output/sayles/[form]/TDDC_heatmaps/)')\n",
    "\n",
    "# used for the title\n",
    "# from https://www.geeksforgeeks.org/how-to-print-superscript-and-subscript-in-python/\n",
    "def get_sub(x): \n",
    "    normal = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+-=()\"\n",
    "    sub_s = \"ₐ₈CDₑբGₕᵢⱼₖₗₘₙₒₚQᵣₛₜᵤᵥwₓᵧZₐ♭꜀ᑯₑբ₉ₕᵢⱼₖₗₘₙₒₚ૧ᵣₛₜᵤᵥwₓᵧ₂₀₁₂₃₄₅₆₇₈₉₊₋₌₍₎\"\n",
    "    res = x.maketrans(''.join(normal), ''.join(sub_s)) \n",
    "    return x.translate(res)\n",
    "\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "if not os.path.exists('../data/output'):\n",
    "    os.makedirs('../data/output')\n",
    "    \n",
    "trial_df = df[(df['trial']==trial)]\n",
    "seg_df = trial_df[trial_df['segment']==seg]\n",
    "\n",
    "start_t = min(seg_df.frame_segment.unique() * config.SAMP_FREQ)\n",
    "end_t = max(seg_df.frame_segment.unique() * config.SAMP_FREQ)\n",
    "\n",
    "## get velocities for the segment (ignore the first frame with NaNs)\n",
    "seg_xvel = seg_df.pivot(index='frame_segment', columns='ID', values='x_vel').to_numpy()[1:] # (num_frames, N)\n",
    "seg_yvel = seg_df.pivot(index='frame_segment', columns='ID', values='y_vel').to_numpy()[1:]\n",
    "\n",
    "## compute TDDC & max tau\n",
    "## - TDDC : (N, N, num_tau, num_frames)\n",
    "## - index (indices of max tau) : (N, N, num_frames)\n",
    "_, TDDC, index = get_TDDC(seg_xvel, seg_yvel, SAMP_FREQ=config.SAMP_FREQ)\n",
    "N = TDDC.shape[0]\n",
    "\n",
    "if i_plotted == None: i_plotted = range(N)\n",
    "if j_plotted == None: j_plotted = range(N)\n",
    "\n",
    "for i in i_plotted:\n",
    "    for j in j_plotted:\n",
    "        if i != j:\n",
    "            # print(i+1,j+1)\n",
    "            title = f'Trial {trial} Segment {seg}'\n",
    "            title += ': TDDC{}(t,$\\\\tau$)'.format(get_sub(str(i+1)+'-'+str(j+1)))\n",
    "            for form in ['png','svg']:\n",
    "                plot_TDDC_ij(TDDC[i,j,:,:], index[i,j,:],\n",
    "                             SAMP_FREQ=config.SAMP_FREQ,\n",
    "                             title=None,     # title,\n",
    "                             saved=saved,\n",
    "                             output_folder=f'../output/sayles/{form}/TDDC_heatmaps/',\n",
    "                             output_file=f'TDDC_trial{int(trial)}_seg{seg}_i{i+1}_j{j+1}',\n",
    "                             output_format=form)\n",
    "                    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting networks (network window size: 1 s)\n",
      "trial 1 -- segment 1 2 3 \n",
      "trial 2 -- segment 1 2 3 4 5 \n",
      "trial 3 -- segment 1 2 3 4 \n",
      "trial 4 -- segment 1 2 3 4 5 \n",
      "trial 5 -- segment 1 2 3 4 5 \n",
      "trial 6 -- segment 1 2 3 4 5 \n",
      "trial 7 -- segment 1 2 5 7 \n",
      "trial 8 -- segment 1 2 3 4 5 \n",
      "trial 9 -- segment 1 2 4 5 \n",
      "trial 10 -- segment 1 3 4 \n",
      "trial 11 -- segment 1 2 3 \n",
      "trial 12 -- segment 1 2 4 \n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import config\n",
    "from utils.get_network import plot_networks\n",
    "\n",
    "# ===== CHANGE THIS ========================================\n",
    "# the size of network time window (in s)\n",
    "ntwk_window_size = config.NTWK_WINDOW_SIZE   # in s\n",
    "# ntwk_window_size = 1\n",
    "# whether to save the image or show\n",
    "saved = True\n",
    "# ==========================================================\n",
    "\n",
    "## init\n",
    "ntwk_window_size_ms = int(ntwk_window_size * 1000)\n",
    "unpruned_weights = pickle.load( open(f'../data/pickle/sayles_weights_unpruned_{ntwk_window_size_ms}ms.p', 'rb') )\n",
    "pruned_weights = pickle.load( open(f'../data/pickle/sayles_weights_pruned_{ntwk_window_size_ms}ms.p', 'rb') )\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "\n",
    "## constant values\n",
    "SAMP_FREQ = config.SAMP_FREQ\n",
    "num_frames_network = int(SAMP_FREQ * ntwk_window_size)\n",
    "\n",
    "## plot networks\n",
    "print('plotting networks (network window size:', ntwk_window_size, 's)')\n",
    "\n",
    "for trial in unpruned_weights.keys():\n",
    "    print('trial', int(trial), '-- segment', end=' ')\n",
    "    trial_df = df[(df['trial']==trial)]\n",
    "\n",
    "    for seg in unpruned_weights[trial].keys():\n",
    "        print(seg, end=' ')\n",
    "        # --- init ---\n",
    "        num_networks, N, _ = unpruned_weights[trial][seg].shape # (num_networks, N, N)\n",
    "        seg_df = trial_df[trial_df['segment']==seg]\n",
    "        # get node positions for each network\n",
    "        x = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                         values='x_transformed').to_numpy()     # values='x'\n",
    "        y = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                         values='y_transformed').to_numpy()     # values='y'\n",
    "        positions = np.stack((x[::num_frames_network, :], \n",
    "                              y[::num_frames_network, :]), \n",
    "                              axis=2)    # (num_networks, N, 2)\n",
    "        # --- plot ---\n",
    "        for form in ['png', 'svg']:\n",
    "            ## unpruned\n",
    "            plot_networks(unpruned_weights[trial][seg], positions,\n",
    "                          order=\"ij\",\n",
    "                          saved=saved,\n",
    "                          title=f'Unpruned networks in Trial{int(trial)} Seg{seg} (network window: {ntwk_window_size}s)',\n",
    "                          output_folder=f'../output/sayles/{form}/networks/weights_{ntwk_window_size_ms}ms/',\n",
    "                          output_file=f'unpruned_trial{int(trial)}_seg{seg}_network',\n",
    "                          output_format=form)\n",
    "            ## pruned \n",
    "            plot_networks(pruned_weights[trial][seg], positions,\n",
    "                          order=\"ij\",\n",
    "                          saved=saved,\n",
    "                          title=f'Pruned networks in Trial{int(trial)} Seg{seg} (network window: {ntwk_window_size}s)',\n",
    "                          output_folder=f'../output/sayles/{form}/networks/weights_{ntwk_window_size_ms}ms/',\n",
    "                          output_file=f'pruned_trial{int(trial)}_seg{seg}_network',\n",
    "                          output_format=form)\n",
    "    print(end='\\n')\n",
    "\n",
    "if (saved):\n",
    "    print('saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting networks for Trial 10 Segment 1 Networks 13 - 32 (network window size: 0.5s)\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "# Plot networks from specific trial, segment, and network IDs for publication\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import config\n",
    "from utils.get_network import plot_networks\n",
    "\n",
    "# ===== CHANGE THIS ========================================\n",
    "# the size of network time window (in s)\n",
    "ntwk_window_size = config.NTWK_WINDOW_SIZE   # in s\n",
    "# ntwk_window_size = 1\n",
    "# whether to save the image or show\n",
    "saved = True\n",
    "# specify networks to plot\n",
    "trial = 10 #5\n",
    "seg = 1 #5\n",
    "start_ntwk_ID = 13 #11  # plot network IDs between start_network and end_network\n",
    "end_ntwk_ID = 32 #15\n",
    "# ==========================================================\n",
    "\n",
    "## init\n",
    "ntwk_window_size_ms = int(ntwk_window_size * 1000)\n",
    "unpruned_weights = pickle.load( open('../data/pickle/sayles_weights_unpruned_' +\n",
    "                                     str(ntwk_window_size_ms) + 'ms.p', 'rb') )\n",
    "pruned_weights = pickle.load( open('../data/pickle/sayles_weights_pruned_' +\n",
    "                                     str(ntwk_window_size_ms) + 'ms.p', 'rb') )\n",
    "df = pd.read_csv('../data/csv/sayles_data_90pct.csv')\n",
    "## constant values\n",
    "SAMP_FREQ = config.SAMP_FREQ\n",
    "num_frames_network = int(SAMP_FREQ * ntwk_window_size)\n",
    "\n",
    "## plot networks\n",
    "\n",
    "# --- init ---\n",
    "print(f'plotting networks for Trial {trial} Segment {seg} Networks {start_ntwk_ID} - {end_ntwk_ID}',\n",
    "      f'(network window size: {ntwk_window_size}s)')\n",
    "trial_df = df[(df['trial']==trial)]\n",
    "num_networks, N, _ = unpruned_weights[trial][seg].shape # (num_networks, N, N)\n",
    "seg_df = trial_df[trial_df['segment']==seg]\n",
    "# get node positions for each network\n",
    "x = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                    values='x_transformed').to_numpy()     # values='x'\n",
    "y = seg_df.pivot(index='frame_segment', columns='ID', \n",
    "                    values='y_transformed').to_numpy()     # values='y'\n",
    "positions = np.stack((x[::num_frames_network, :], \n",
    "                        y[::num_frames_network, :]), \n",
    "                        axis=2)    # (num_networks, N, 2)\n",
    "\n",
    "# --- plot ---\n",
    "for form in ['png', 'svg']:\n",
    "    ## unpruned\n",
    "    plot_networks(unpruned_weights[trial][seg][start_ntwk_ID:end_ntwk_ID+1,:,:],\n",
    "                  positions[start_ntwk_ID:end_ntwk_ID+1,:,:],\n",
    "                  order=\"ij\",\n",
    "                  saved=saved,\n",
    "                  subtitle='', # no title\n",
    "                  output_folder=f\"../output/sayles/{form}/networks/publication/\",\n",
    "                  output_file=f\"unpruned_trial{trial}_seg{seg}_ntwk{start_ntwk_ID}to{end_ntwk_ID}_{ntwk_window_size_ms}ms\",\n",
    "                  output_format=form)\n",
    "    ## pruned \n",
    "    plot_networks(pruned_weights[trial][seg][start_ntwk_ID:end_ntwk_ID+1,:,:], \n",
    "                  positions[start_ntwk_ID:end_ntwk_ID+1,:,:],\n",
    "                  order=\"ij\",\n",
    "                  saved=saved,\n",
    "                  subtitle='',   # no title\n",
    "                  output_folder=f\"../output/sayles/{form}/networks/publication/\",\n",
    "                  output_file=f\"pruned_trial{trial}_seg{seg}_ntwk{start_ntwk_ID}to{end_ntwk_ID}_{ntwk_window_size_ms}ms\",\n",
    "                  output_format=form)\n",
    "\n",
    "if (saved):\n",
    "    print('saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how much the networks changed due to pruning\n",
    "Compare the number of edges before vs. after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of all possible edges: 391160\n",
      "the number of non-zero edges before pruning: 191020 (48.83% of all possible edges)\n",
      "the number of edges that got pruned: 97609 (24.95% of all possible edges; 51.1% of the edges initially found)\n",
      "--------\n",
      "This leaves 93411 edges (23.88% of all possible edges) in place\n",
      "\n",
      "the number of all possible edges if they were undirected: 195580\n",
      "the number of non-zero undirected edges before pruning: 166544 (85.15% of all possible undirected edges)\n",
      "the number of non-zero undirected edges after pruning: 84367 (43.14% of all possible undirected edges; 50.66% of the edges initially found)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import config\n",
    "\n",
    "# ===== CHANGE THIS ========================================\n",
    "# the size of network time window (in s)\n",
    "ntwk_window_size = config.NTWK_WINDOW_SIZE   # in s\n",
    "# ==========================================================\n",
    "\n",
    "## init\n",
    "ntwk_window_size_ms = int(ntwk_window_size * 1000)\n",
    "unpruned_weights = pickle.load( open(f'../data/pickle/sayles_weights_unpruned_{ntwk_window_size_ms}ms.p', 'rb') )\n",
    "pruned_weights = pickle.load( open(f'../data/pickle/sayles_weights_pruned_{ntwk_window_size_ms}ms.p', 'rb') )\n",
    "\n",
    "num_all_possible_edges = 0\n",
    "num_TDDC_edges = 0       # the number of non-zero edges before pruning\n",
    "num_pruned_edges = 0          # the number of edges that got pruned\n",
    "\n",
    "# count the number of links if they were undirected\n",
    "num_undirected_TDDC_edges = 0\n",
    "num_undirected_pruned_edges = 0\n",
    "\n",
    "for trial in unpruned_weights.keys():\n",
    "    for seg in unpruned_weights[trial].keys():\n",
    "        # unpruned_weights[trial][seg] : (num_networks, N, N)\n",
    "        num_networks, N, _ = unpruned_weights[trial][seg].shape\n",
    "\n",
    "        # check the number of TDDC edges (not zero or nan)\n",
    "        unpruned_mask = (unpruned_weights[trial][seg] != 0)     # True if not 0, False if 0\n",
    "        unpruned_mask[np.isnan(unpruned_weights[trial][seg])] = False   # False if NaN\n",
    "        for n in range(num_networks):   # self-link should be False\n",
    "            np.fill_diagonal(unpruned_mask[n], False)\n",
    "\n",
    "        # check the number of pruned edges\n",
    "        pruned_mask = (unpruned_weights[trial][seg] != pruned_weights[trial][seg])    # True if pruned; False if the same\n",
    "        pruned_mask[np.isnan(unpruned_weights[trial][seg]) | np.isnan(pruned_weights[trial][seg])] = False  # False if NaN\n",
    "        for n in range(num_networks):   # self-link should be False\n",
    "            np.fill_diagonal(pruned_mask[n], False)\n",
    "\n",
    "        # check the number of links if we \n",
    "        undirected_unpruned_mask = unpruned_mask | np.transpose(unpruned_mask, axes=(0, 2, 1))\n",
    "        undirected_pruned_mask = pruned_mask | np.transpose(pruned_mask, axes=(0, 2, 1))\n",
    "\n",
    "        num_all_possible_edges += num_networks * (N * N - N)      # exclude edge to the same node (i to i)\n",
    "        num_TDDC_edges += np.count_nonzero(unpruned_mask)\n",
    "        num_pruned_edges += np.count_nonzero(pruned_mask)\n",
    "\n",
    "        num_undirected_TDDC_edges += int(np.count_nonzero(undirected_unpruned_mask)/2)\n",
    "        num_undirected_pruned_edges += int(np.count_nonzero(undirected_pruned_mask)/2)\n",
    "\n",
    "# print(round(num_pruned_edges/num_total_edges*100,2), \"% of edges were pruned\")\n",
    "print(f\"the number of all possible edges: {num_all_possible_edges}\")\n",
    "print(f\"the number of non-zero edges before pruning: {num_TDDC_edges} ({round(num_TDDC_edges/num_all_possible_edges*100, 2)}% of all possible edges)\")\n",
    "print(f\"the number of edges that got pruned: {num_pruned_edges} ({round(num_pruned_edges/num_all_possible_edges*100, 2)}% of all possible edges;\",\n",
    "      f\"{round(num_pruned_edges/num_TDDC_edges*100, 2)}% of the edges initially found)\")\n",
    "print(\"--------\")\n",
    "print(f\"This leaves {num_TDDC_edges-num_pruned_edges} edges ({round((num_TDDC_edges-num_pruned_edges)/num_all_possible_edges*100, 2)}% of all possible edges) in place\")\n",
    "\n",
    "\n",
    "num_all_possible_undirected_edges = int(num_all_possible_edges/2)\n",
    "print()\n",
    "print(f\"the number of all possible edges if they were undirected: {num_all_possible_undirected_edges}\")\n",
    "print(f\"the number of non-zero undirected edges before pruning: {num_undirected_TDDC_edges} ({round(num_undirected_TDDC_edges/num_all_possible_undirected_edges*100, 2)}% of all possible undirected edges)\")\n",
    "print(f\"the number of non-zero undirected edges after pruning: {num_undirected_pruned_edges} ({round(num_undirected_pruned_edges/num_all_possible_undirected_edges*100, 2)}% of all possible undirected edges; {round(num_undirected_pruned_edges/num_undirected_TDDC_edges*100, 2)}% of the edges initially found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distribution of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Save network weights for all relevant network time windows\n",
    "Run the `Get network weights` section to get network weights for relevant time windows: `0.5s, 1s, 2s`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "## ====== change ONLY HERE ============\n",
    "ntwk_window_sizes = [0.5]\n",
    "## ====================================\n",
    "\n",
    "\n",
    "for ntwk_window_size in ntwk_window_sizes:\n",
    "\n",
    "    ntwk_window_size_ms = int(ntwk_window_size * 1000)\n",
    "    weights = {}\n",
    "\n",
    "    for prune_type in ['unpruned', 'pruned']:\n",
    "        weights[prune_type] = []\n",
    "        data = pickle.load( open(f'../data/pickle/sayles_weights_{prune_type}_{ntwk_window_size_ms}ms.p', 'rb') )\n",
    "        for trial in data.keys():\n",
    "            for seg in data[trial].keys():\n",
    "                num_networks, N, _ = data[trial][seg].shape\n",
    "                mask = ~np.eye(N, dtype=bool)\n",
    "                weights[prune_type].extend(data[trial][seg][:, mask].flatten())\n",
    "\n",
    "    bins = np.arange(0, 1.2, 0.1)\n",
    "\n",
    "    # Calculate frequency counts for unpruned and pruned data\n",
    "    freq_unpruned, _ = np.histogram(weights['unpruned'], bins=bins)\n",
    "    freq_pruned, _ = np.histogram(weights['pruned'], bins=bins)\n",
    "\n",
    "    # Plot the histogram with grouped bars\n",
    "    bar_width = 0.4\n",
    "    opacity = 1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 5))\n",
    "\n",
    "    index = np.arange(len(bins) - 1)\n",
    "    rects1 = ax.bar(index - bar_width/2, freq_unpruned, bar_width, alpha=opacity, color='tab:blue', label='Unpruned')\n",
    "    rects2 = ax.bar(index + bar_width/2, freq_pruned, bar_width, alpha=opacity, color='tab:orange', label='Pruned')\n",
    "\n",
    "    ax.set_xlabel('Weight')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    if len(weights['unpruned']) != len(weights['pruned']):\n",
    "        raise ValueError(\"something is wrong: # of edges\")\n",
    "    title = f\"Distribution of {ntwk_window_size}s network weights (Unpruned vs Pruned)\\ntotal: {len(weights['unpruned'])} edges\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels([f'{bins[i]:.1f}-{bins[i+1]:.1f}' for i in range(len(bins) - 1)])\n",
    "    ax.legend()\n",
    "    ax.grid(True, axis='y')\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 2),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for form in ['png', 'svg']:\n",
    "        new_folder = f'../output/sayles/{form}/weights_distrubution/'\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        plt.savefig(os.path.join(new_folder, f'weight_distribution_{ntwk_window_size_ms}ms.{form}'))\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
